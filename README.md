# Visual Studio Local LLM Plugin - With Ollama - Extra Tool

## Project Objective: 
To get help from Local AI quickly on Visual Studio. Thanks to Local LLM, to ensure project security and prevent code leaks. At the same time, to make a tool that provides convenience in terms of certain functions.

## How does it work?

While working on Visual Studio. you can use the tools you want by opening the tool with the key combination you will assign. You can get help from artificial intelligence by writing a message. You can send the codes you choose to the artificial intelligence with a single button and have it work on those codes. 

## Assignment Process:
Visual Studio - Tools - Keyboard - Whow Commands Containing LocalLLLMPlug


## Supported Servers.
OLLAMA

## Supported Models:
deeepseek-r1
llama3.3
phi4
nomic-embed-text
mistral
qwen
gemma
llava
qwen2.5-code
mxbai-embed-large
starcoder2

## Extra Features:

Deleting refreshed data.

Delete before or after a specific word.

Adding a specific word to the beginning or end.

Quickly replace a specific part in the code with multiple data.

