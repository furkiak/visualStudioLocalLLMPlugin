# Visual Studio Local LLM Plugin - With Ollama - Extra Tool

## Project Objective: 
To get help from Local AI quickly on Visual Studio. Thanks to Local LLM, to ensure project security and prevent code leaks. At the same time, to make a tool that provides convenience in terms of certain functions.

## How does it work?

While working on Visual Studio. You can use the tools you want by opening the tool with the CTRL + 3 combination. You can get help from artificial intelligence by writing a message. You can send your selected codes to artificial intelligence with a single button and make it work on those codes. 

## Supported Servers.
OLLAMA

## Supported Models:
deeepseek-r1
llama3.3
phi4
nomic-embed-text
mistral
qwen
gemma
llava
qwen2.5-code
mxbai-embed-large
starcoder2

## Extra Features:
Deleting refreshed data.
Delete before or after a specific word.
Adding a specific word to the beginning or end.
Quickly replace a specific part in the code with multiple data.
